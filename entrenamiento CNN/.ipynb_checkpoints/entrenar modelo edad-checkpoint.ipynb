{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5564e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('age_gender.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f89ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pixels'] = data['pixels'].apply(lambda x: np.array(x.split(), dtype='float32').reshape(48, 48))# Cambia a la ruta de tu archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce41d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(data['pixels'].values) / 255.0\n",
    "X = X.reshape(-1, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436abf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='linear')  # Cambiar a 1 salida y activación lineal\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fb82049",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - loss: 482.3643 - mae: 16.8264 - val_loss: 258.5425 - val_mae: 11.9199\n",
      "Epoch 2/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 40ms/step - loss: 262.8578 - mae: 12.4478 - val_loss: 380.3854 - val_mae: 14.8158\n",
      "Epoch 3/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 42ms/step - loss: 243.6750 - mae: 11.8848 - val_loss: 189.0170 - val_mae: 10.1210\n",
      "Epoch 4/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 40ms/step - loss: 217.3691 - mae: 11.1208 - val_loss: 202.2165 - val_mae: 10.4049\n",
      "Epoch 5/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 41ms/step - loss: 195.2475 - mae: 10.5183 - val_loss: 181.9973 - val_mae: 9.7978\n",
      "Epoch 6/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 41ms/step - loss: 193.6530 - mae: 10.4838 - val_loss: 159.9074 - val_mae: 9.1654\n",
      "Epoch 7/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step - loss: 177.3729 - mae: 9.9689 - val_loss: 134.1991 - val_mae: 8.4859\n",
      "Epoch 8/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step - loss: 170.9685 - mae: 9.7934 - val_loss: 167.1152 - val_mae: 9.3875\n",
      "Epoch 9/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step - loss: 160.7031 - mae: 9.4996 - val_loss: 145.0513 - val_mae: 8.7198\n",
      "Epoch 10/10\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - loss: 158.7557 - mae: 9.3881 - val_loss: 122.2545 - val_mae: 8.1032\n",
      "¡Modelo guardado como 'modelo_prediccion_edad.h5'!\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='linear')  # Cambiar a 1 salida y activación lineal\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Paso 4: Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Paso 5: Guardar el modelo\n",
    "# model.save('modelo_prediccion_edad.h5')\n",
    "\n",
    "print(\"¡Modelo guardado como 'modelo_prediccion_edad.h5'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cc9d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb36b9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002C92E31B790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002C92E31B790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Age: 6, Predicted Age: 10.29\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo CSV\n",
    "data = pd.read_csv(\"age_gender.csv\")\n",
    "\n",
    "# Cargar el modelo previamente guardado\n",
    "model = load_model(\"modelo_prediccion_edad.h5\", custom_objects={'mse': MeanSquaredError()})\n",
    "\n",
    "# Seleccionar una fila aleatoria del CSV\n",
    "random_row = data.sample(1)\n",
    "\n",
    "# Obtener los píxeles de la imagen de la fila seleccionada\n",
    "pixels = random_row['pixels'].values[0]\n",
    "\n",
    "# Convertir la cadena de texto de los píxeles a una lista de enteros\n",
    "pixels = np.array([int(i) for i in pixels.split()])\n",
    "\n",
    "# Asegurarse de que los píxeles tengan forma (48, 48) (ajusta si es necesario)\n",
    "pixels = pixels.reshape(48, 48)\n",
    "\n",
    "# Preprocesar la imagen\n",
    "pixels = np.expand_dims(pixels, axis=0)  # Añadir dimensión para el batch\n",
    "pixels = np.expand_dims(pixels, axis=-1)  # Añadir dimensión para canal (grayscale)\n",
    "\n",
    "# Normalizar los valores a [0, 1]\n",
    "pixels = pixels / 255.0\n",
    "\n",
    "# Realizar predicción\n",
    "predicted_age = model.predict(pixels)[0][0]  # Predecir la edad continua\n",
    "\n",
    "# Mostrar la imagen y el resultado\n",
    "plt.imshow(pixels.squeeze(), cmap='gray')  # .squeeze() para eliminar dimensiones adicionales\n",
    "plt.axis('off')  # Quitar los ejes\n",
    "plt.title(f\"Predicted Age: {predicted_age:.2f}\")\n",
    "plt.show()\n",
    "\n",
    "# Mostrar la edad real (si tienes esa información en el CSV)\n",
    "real_age = random_row['age'].values[0]\n",
    "print(f'Real Age: {real_age}, Predicted Age: {predicted_age:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41a9d9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 - 2s - 13ms/step - loss: 78.9112 - mean_absolute_error: 6.5996\n",
      "Pérdida (Loss): 78.91122436523438\n",
      "MAE: 6.599600791931152\n"
     ]
    }
   ],
   "source": [
    "model = load_model('gender_model.h5')\n",
    "\n",
    "resultados = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Pérdida (Loss):\", resultados[0])\n",
    "print(\"MAE:\", resultados[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cad81e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de la salida del modelo: (None, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma de la salida del modelo:\", model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83a05572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva forma de y_test: (4741,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Expandir dimensiones de y_test si es necesario\n",
    "if len(model.output_shape) > 2:\n",
    "    y_test = np.expand_dims(y_test, axis=-1)\n",
    "print(\"Nueva forma de y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71397fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva forma de y_test: (4741, 2)\n"
     ]
    }
   ],
   "source": [
    "# Replicar valores de y_test para crear dos columnas\n",
    "y_test = np.stack([y_test, y_test], axis=-1)\n",
    "print(\"Nueva forma de y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca12017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d815f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a905816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca18e84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d504625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d13e83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar el CSV\n",
    "data = pd.read_csv('age_gender.csv')\n",
    "\n",
    "# Convertir la columna \"pixels\" a una matriz numérica\n",
    "def procesar_pixels(pixel_str):\n",
    "    # Convertir la cadena de píxeles a una lista de enteros\n",
    "    pixel_values = np.array([int(pixel) for pixel in pixel_str.split()], dtype=np.float32)\n",
    "    # Normalizar los valores de píxeles (0-255 -> 0-1)\n",
    "    return pixel_values / 255.0\n",
    "\n",
    "# Aplicar la función a todas las filas\n",
    "X = np.array(data['pixels'].apply(procesar_pixels).tolist())\n",
    "X = X.reshape(-1, 48, 48, 1)  # Ajustar al tamaño (48x48x1) para imágenes en escala de grises\n",
    "\n",
    "# Etiquetas: Edad\n",
    "y = data['age'].values\n",
    "\n",
    "# Dividir datos en conjuntos de prueba y entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d435d890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/mean_squared_error/sub defined at (most recent call last):\n  File \"C:\\My programers\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"C:\\My programers\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n\n  File \"C:\\My programers\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"C:\\My programers\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"C:\\My programers\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n\n  File \"C:\\Users\\win\\AppData\\Local\\Temp\\ipykernel_13588\\3848518393.py\", line 5, in <module>\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 425, in evaluate\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 161, in one_step_on_iterator\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 150, in one_step_on_data\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 81, in test_step\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 316, in compute_loss\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 609, in __call__\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 645, in call\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\losses\\loss.py\", line 43, in __call__\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 22, in call\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1158, in mean_squared_error\n\nIncompatible shapes: [32] vs. [32,2]\n\t [[{{node compile_loss/mean_squared_error/sub}}]] [Op:__inference_one_step_on_iterator_262646]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13588\\3848518393.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Evaluar el modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresultados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pérdida (Loss):\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresultados\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\My programers\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/mean_squared_error/sub defined at (most recent call last):\n  File \"C:\\My programers\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"C:\\My programers\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n\n  File \"C:\\My programers\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"C:\\My programers\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"C:\\My programers\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n\n  File \"C:\\Users\\win\\AppData\\Local\\Temp\\ipykernel_13588\\3848518393.py\", line 5, in <module>\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 425, in evaluate\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 161, in one_step_on_iterator\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 150, in one_step_on_data\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 81, in test_step\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 316, in compute_loss\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 609, in __call__\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 645, in call\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\losses\\loss.py\", line 43, in __call__\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 22, in call\n\n  File \"C:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1158, in mean_squared_error\n\nIncompatible shapes: [32] vs. [32,2]\n\t [[{{node compile_loss/mean_squared_error/sub}}]] [Op:__inference_one_step_on_iterator_262646]"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo\n",
    "modelo = load_model('age_prediction_model.h5')\n",
    "\n",
    "# Evaluar el modelo\n",
    "resultados = modelo.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Pérdida (Loss):\", resultados[0])\n",
    "print(\"Precisión:\", resultados[1])  # Solo se mostrará si el modelo fue compilado con 'accuracy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe225d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_test: (4741, 48, 48, 1)\n",
      "Forma de y_test: (4741,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52750053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva forma de y_test: (4741,)\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test.reshape(-1)\n",
    "print(\"Nueva forma de y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a35d7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 6400, but received input with shape (1, 186624)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1, 224, 224, 1), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13588\\2397978697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# Calcular los gradientes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_input_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Paso 5: Graficar el gradiente de la imagen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13588\\2397978697.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[1;34m(image, label)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Hacemos que el tape observe la imagen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Predicción\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Calculamos la pérdida\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Gradientes con respecto a la imagen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\My programers\\Anaconda3\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                 }:\n\u001b[1;32m--> 227\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m    228\u001b[0m                         \u001b[1;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                         \u001b[1;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 6400, but received input with shape (1, 186624)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1, 224, 224, 1), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2  # Usaremos OpenCV para la conversión a escala de grises\n",
    "\n",
    "# Paso 1: Cargar el modelo .h5\n",
    "model = tf.keras.models.load_model('gender_model.h5')\n",
    "\n",
    "# Paso 2: Compilar el modelo (por si no está compilado)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Paso 3: Obtener las entradas y salidas del modelo\n",
    "input_image = model.inputs[0]  # La entrada del modelo\n",
    "output_layer = model.outputs[0]  # La salida del modelo (predicción)\n",
    "\n",
    "# Definir una función de pérdida (por ejemplo, la pérdida de entropía cruzada)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Función para calcular los gradientes\n",
    "def compute_gradients(image, label):\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)  # Convertimos a tensor\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)  # Hacemos que el tape observe la imagen\n",
    "        predictions = model(image)  # Predicción\n",
    "        loss = loss_fn(label, predictions)  # Calculamos la pérdida\n",
    "    gradients = tape.gradient(loss, image)  # Gradientes con respecto a la imagen\n",
    "    return gradients\n",
    "\n",
    "# Paso 4: Seleccionar una imagen de entrada y su etiqueta (esto depende de tu conjunto de datos)\n",
    "# Aquí estoy usando un ejemplo de imagen aleatoria (asegúrate de usar datos reales)\n",
    "image_input = np.random.rand(224, 224, 3)  # Ejemplo de una imagen RGB de 224x224\n",
    "\n",
    "# Convertir la imagen a escala de grises si el modelo espera una imagen con un solo canal\n",
    "image_input_gray = cv2.cvtColor(image_input.astype(np.float32), cv2.COLOR_RGB2GRAY)\n",
    "image_input_gray = np.expand_dims(image_input_gray, axis=-1)  # Aseguramos que la forma sea (224, 224, 1)\n",
    "\n",
    "# Hacer que la imagen tenga la forma correcta para la entrada del modelo\n",
    "image_input_gray = np.expand_dims(image_input_gray, axis=0)  # Añadir dimensión batch\n",
    "\n",
    "label = np.array([0])  # Etiqueta ficticia\n",
    "\n",
    "# Calcular los gradientes\n",
    "gradients = compute_gradients(image_input_gray, label)\n",
    "\n",
    "# Paso 5: Graficar el gradiente de la imagen\n",
    "gradients = gradients.numpy().squeeze()  # Eliminamos dimensiones adicionales (si es necesario)\n",
    "\n",
    "# Mostrar los gradientes para la imagen\n",
    "plt.imshow(gradients, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Gradiente de la Imagen')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df343d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
