{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # Para manejar imágenes nuevas\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV\n",
    "data = pd.read_csv('age_gender.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir píxeles en arrays de numpy\n",
    "data['pixels'] = data['pixels'].apply(lambda x: np.array(x.split(), dtype=\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar los datos\n",
    "X = np.array(data['pixels'].tolist())\n",
    "X = X.reshape(X.shape[0], 48, 48, 1) / 255.0  # Normalizar los píxeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219203650636.jpg.chip.jpg</td>\n",
       "      <td>[129.0, 128.0, 128.0, 126.0, 127.0, 130.0, 133...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222752047.jpg.chip.jpg</td>\n",
       "      <td>[164.0, 74.0, 111.0, 168.0, 169.0, 171.0, 175....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222832191.jpg.chip.jpg</td>\n",
       "      <td>[67.0, 70.0, 71.0, 70.0, 69.0, 67.0, 70.0, 79....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144911423.jpg.chip.jpg</td>\n",
       "      <td>[193.0, 197.0, 198.0, 200.0, 199.0, 200.0, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144914327.jpg.chip.jpg</td>\n",
       "      <td>[202.0, 205.0, 209.0, 210.0, 209.0, 209.0, 210...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  ethnicity  gender                        img_name  \\\n",
       "0    1          2       0  20161219203650636.jpg.chip.jpg   \n",
       "1    1          2       0  20161219222752047.jpg.chip.jpg   \n",
       "2    1          2       0  20161219222832191.jpg.chip.jpg   \n",
       "3    1          2       0  20161220144911423.jpg.chip.jpg   \n",
       "4    1          2       0  20161220144914327.jpg.chip.jpg   \n",
       "\n",
       "                                              pixels  \n",
       "0  [129.0, 128.0, 128.0, 126.0, 127.0, 130.0, 133...  \n",
       "1  [164.0, 74.0, 111.0, 168.0, 169.0, 171.0, 175....  \n",
       "2  [67.0, 70.0, 71.0, 70.0, 69.0, 67.0, 70.0, 79....  \n",
       "3  [193.0, 197.0, 198.0, 200.0, 199.0, 200.0, 202...  \n",
       "4  [202.0, 205.0, 209.0, 210.0, 209.0, 209.0, 210...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['age']  # Variable objetivo: edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear etiquetas para rango de edad\n",
    "y_min = data['age'] - 2  # Edad mínima estimada (2 años menos)\n",
    "y_max = data['age'] + 2  # Edad máxima estimada (2 años más)\n",
    "y_range = np.vstack((y_min, y_max)).T  # Combinar en una sola matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_range, test_size=0.22, random_state=37\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonio/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo de red neuronal convolucional\n",
    "model = tf.keras.Sequential([\n",
    "    L.InputLayer(input_shape=(48, 48, 1)),\n",
    "    L.Conv2D(32, (3, 3), activation='relu'),  # 1 CV\n",
    "    L.BatchNormalization(),  # 1 BT NM\n",
    "    L.MaxPooling2D((2, 2)),  # 1 MP\n",
    "    L.Conv2D(64, (3, 3), activation='relu'),  # 2 CV\n",
    "    L.MaxPooling2D((2, 2)),  # 2 MP\n",
    "    L.Conv2D(128, (3, 3), activation='relu'),  # 3 CV\n",
    "    L.MaxPooling2D((2, 2)),  # 3 MP\n",
    "    L.Flatten(),\n",
    "    L.Dense(64, activation='relu'),  # 64 Neuronas\n",
    "    L.Dropout(rate=0.5),  # 2 NM DP\n",
    "    L.Dense(2, activation='linear')  # Predicción: Edad mínima y máxima\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback para detener el entrenamiento temprano\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('val_loss') < 110:\n",
    "            print(\"\\nReached 110 val_loss so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - loss: 149.8247 - mae: 9.1378 - val_loss: 201.9528 - val_mae: 11.3062\n",
      "Epoch 2/20\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 52ms/step - loss: 140.8590 - mae: 8.7641 - val_loss: 154.2560 - val_mae: 8.9957\n",
      "Epoch 3/20\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 127.7072 - mae: 8.3658\n",
      "Reached 110 val_loss so cancelling training!\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - loss: 127.7069 - mae: 8.3658 - val_loss: 107.0964 - val_mae: 7.8166\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=20, validation_split=0.1, batch_size=64, callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error: 97.41747283935547\n",
      "Test Mean Absolute Error: 7.51378870010376\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "mse, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Mean Squared Error: {mse}')\n",
    "print(f'Test Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'age_prediction_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('age_prediction_model.h5')\n",
    "print(\"Modelo guardado como 'age_prediction_model.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar el modelo y predecir\n",
    "\n",
    "def predict_age_1(image_path, model_path):\n",
    "    try:\n",
    "        # Cargar el modelo\n",
    "        loaded_model = tf.keras.models.load_model(model_path)\n",
    "        print(\"Modelo cargado correctamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el modelo: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Preprocesar la imagen\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error: No se pudo cargar la imagen desde {image_path}.\")\n",
    "            return None\n",
    "        img = cv2.resize(img, (48, 48))  # Redimensionar a 48x48\n",
    "        img = img.reshape(1, 48, 48, 1) / 255.0  # Normalizar\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar la imagen: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Predecir la edad\n",
    "        predicted_age = loaded_model.predict(img)\n",
    "        print(f'Edad estimada: {predicted_age[0][0]:.2f} años normal')\n",
    "        return predicted_age[0][0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la predicción: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir rango de edad\n",
    "def predict_age_range(image_path, model_path='age_range_prediction_model.h5'):\n",
    "    # Cargar el modelo\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "    print(\"Modelo cargado correctamente.\")\n",
    "\n",
    "    # Cargar la imagen y convertirla a escala de grises\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Error: No se pudo cargar la imagen desde {image_path}.\")\n",
    "        return None\n",
    "\n",
    "    # Usar un detector de rostros para recortar automáticamente el rostro\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        print(\"No se detectó ningún rostro en la imagen.\")\n",
    "        return None\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = img[y:y+h, x:x+w]  # Recortar el rostro\n",
    "        face = cv2.resize(face, (48, 48))  # Redimensionar a 48x48\n",
    "        face = face.reshape(1, 48, 48, 1) / 255.0  # Normalizar\n",
    "        break  # Solo se toma el primer rostro\n",
    "\n",
    "    # Hacer la predicción\n",
    "    predicted_range = loaded_model.predict(face)\n",
    "    age_min, age_max = predicted_range[0]\n",
    "    print(f'Rango de edad estimado: {age_min:.1f} - {age_max:.1f} años')\n",
    "    return age_min, age_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edad estimada: 35.06 años normal\n",
      "Modelo cargado correctamente.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Edad estimada: 19.80 años con Cascade\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.79531"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = 'Yooo.jpg'\n",
    "model_path = 'age_prediction_model.h5'\n",
    "\n",
    "predict_age(image_path, model_path)\n",
    "predict_age_range(image_path, model_path)\n",
    "#predict_age_CV(image_path, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
