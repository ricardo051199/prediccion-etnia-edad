{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 20:02:13.919151: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import layers as L\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # Para manejar imágenes nuevas\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV\n",
    "data = pd.read_csv('age_gender.csv')\n",
    "# Procesar\n",
    "data['pixels'] = data['pixels'].apply(lambda x: np.array(x.split(), dtype=\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar los datos, normalizar \n",
    "X = np.array(data['pixels'].tolist())\n",
    "X = X.reshape(X.shape[0], 48, 48, 1) / 255.0 \n",
    "y = data['gender']  # Variable objetivo: genero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219203650636.jpg.chip.jpg</td>\n",
       "      <td>[129.0, 128.0, 128.0, 126.0, 127.0, 130.0, 133...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222752047.jpg.chip.jpg</td>\n",
       "      <td>[164.0, 74.0, 111.0, 168.0, 169.0, 171.0, 175....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222832191.jpg.chip.jpg</td>\n",
       "      <td>[67.0, 70.0, 71.0, 70.0, 69.0, 67.0, 70.0, 79....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144911423.jpg.chip.jpg</td>\n",
       "      <td>[193.0, 197.0, 198.0, 200.0, 199.0, 200.0, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144914327.jpg.chip.jpg</td>\n",
       "      <td>[202.0, 205.0, 209.0, 210.0, 209.0, 209.0, 210...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  ethnicity  gender                        img_name  \\\n",
       "0    1          2       0  20161219203650636.jpg.chip.jpg   \n",
       "1    1          2       0  20161219222752047.jpg.chip.jpg   \n",
       "2    1          2       0  20161219222832191.jpg.chip.jpg   \n",
       "3    1          2       0  20161220144911423.jpg.chip.jpg   \n",
       "4    1          2       0  20161220144914327.jpg.chip.jpg   \n",
       "\n",
       "                                              pixels  \n",
       "0  [129.0, 128.0, 128.0, 126.0, 127.0, 130.0, 133...  \n",
       "1  [164.0, 74.0, 111.0, 168.0, 169.0, 171.0, 175....  \n",
       "2  [67.0, 70.0, 71.0, 70.0, 69.0, 67.0, 70.0, 79....  \n",
       "3  [193.0, 197.0, 198.0, 200.0, 199.0, 200.0, 202...  \n",
       "4  [202.0, 205.0, 209.0, 210.0, 209.0, 209.0, 210...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.22, random_state=37\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/solangelquiroga/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo de red neuronal convolucional\n",
    "model = tf.keras.Sequential([\n",
    "    L.InputLayer(input_shape=(48, 48, 1)),\n",
    "    L.Conv2D(32, (3, 3), activation='relu'),  \n",
    "    L.BatchNormalization(),  # 1 BT NM\n",
    "    L.MaxPooling2D((2, 2)),  # 1 MP\n",
    "    L.Conv2D(64, (3, 3), activation='relu'),  \n",
    "    L.MaxPooling2D((2, 2)),  # 2 MP\n",
    "    L.Conv2D(128, (3, 3), activation='relu'), \n",
    "    L.MaxPooling2D((2, 2)),  # 3 MP\n",
    "    L.Flatten(),\n",
    "    L.Dense(64, activation='relu'),  # 64 Neuronas\n",
    "    L.Dropout(0.5),  # 2 NM DP\n",
    "    L.Dense(1, activation='sigmoid')  # genero\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback para detener el entrenamiento temprano\n",
    "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('val_accuracy') > 0.85:  # Parar con accuracy alto\n",
    "            print(\"\\nReached high validation accuracy, stopping training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 162ms/step - accuracy: 0.7275 - loss: 0.5259 - val_accuracy: 0.7718 - val_loss: 0.5513\n",
      "Epoch 2/20\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8623 - loss: 0.3110\n",
      "Reached high validation accuracy, stopping training!\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 157ms/step - accuracy: 0.8624 - loss: 0.3110 - val_accuracy: 0.8680 - val_loss: 0.3345\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=20, \n",
    "    validation_split=0.1, \n",
    "    batch_size=64, \n",
    "    callbacks=[EarlyStoppingCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.32469624280929565\n",
      "Test Accuracy: 0.8696318864822388\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'gender_prediction_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('gender_prediction_model.h5')\n",
    "print(\"Modelo guardado como 'gender_prediction_model.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(image_path, model_path):\n",
    "    try:\n",
    "        # Cargar modelo\n",
    "        loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "        # Preprocesar imagen (versión mejorada)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error: Could not load image from {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Redimensionar\n",
    "        img = cv2.resize(img, (48, 48))\n",
    "        \n",
    "        # Normalizar\n",
    "        img = img / 255.0\n",
    "        \n",
    "        # Opcional: Función de aumento de datos (si la implementas)\n",
    "        # img = aumentar_imagen(img)\n",
    "        \n",
    "        # Reshape para modelo\n",
    "        img = img.reshape(1, 48, 48, 1)\n",
    "        \n",
    "        # Predicción\n",
    "        prediction = loaded_model.predict(img)\n",
    "        \n",
    "        # Interpretar resultado\n",
    "        gender = \"Female\" if prediction[0][0] > 0.5 else \"Male\"\n",
    "        confidence = prediction[0][0] if gender == \"Female\" else 1 - prediction[0][0]\n",
    "        \n",
    "        # Imprimir resultados\n",
    "        print(f'Predicted Gender: {gender}')\n",
    "        print(f'Confidence: {confidence:.2%}')\n",
    "        \n",
    "        # Devolver diccionario con resultados\n",
    "        return {\n",
    "            \"gender\": gender,\n",
    "            \"confidence\": float(confidence)\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función opcional de aumento de datos (para implementar)\n",
    "def aumentar_imagen(img):\n",
    "    # Ejemplo de técnicas de aumento de datos\n",
    "    # Puedes añadir más técnicas según necesites\n",
    "    \n",
    "    # Rotación ligera\n",
    "    rows, cols = img.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), np.random.randint(-10, 10), 1)\n",
    "    img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    \n",
    "    # Añadir ruido\n",
    "    noise = np.random.normal(0, 0.1, img.shape).astype(np.float32)\n",
    "    img = np.clip(img + noise, 0, 1)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Predicted Gender: Male\n",
      "Confidence: 84.19%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Male'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = 'Yooo.jpg'\n",
    "model_path = 'gender_prediction_model.h5'\n",
    "predict_gender(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'img1.jpeg'\n",
    "model_path = 'gender_prediction_model.h5'\n",
    "predict_gender(image_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'img2.jpeg'\n",
    "model_path = 'gender_prediction_model.h5'\n",
    "predict_gender(image_path, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
